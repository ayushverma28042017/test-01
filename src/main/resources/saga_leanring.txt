
https://www.youtube.com/watch?v=YPbGW3Fnmbc
Using sagas to maintain data consistency in a microservice architecture by Chris Richardson

how to maintain data consisency in MS archi:

Why there is problem ?
Why tradation 2PC is not an option of MS archit.
Concept of SAGA :transaction Model



Why there is problem ?
Why ACID is not a option, when trasnaciton span multiple service ,so SAGA comes, 
Invariant: nver be vilated: never allow cusotme to place order ,where credit limit is voilated
Eg: @trnsation: got to cutoemr table, order table, then commits.
SQL BEGIN Trasnaiton:
	file the credit limit of cusotmer
	select order total
	get credit limti fo customer
	insert inot modle
	Commit transation
-IF conncuent for same customer, property, of ACID ,ISolation leve, and 
-current transation for the same custoemr is seralise.
-MS: set of loosely couples services
-MS: paraallelize software development
-MS: new tech stack adoption is easy
-Each service have own DB, or private data, if servier communication via db, it is not loosely couple
-defate the purpsoe of MS, parellel dev by autonomous team, so only way service interact each other via API
- but how data consistency maintain if comm via API
-2PC: single point of failutre
	  with retry : O^2
	  most DB dont support distributed transtaion
	  CAP :: 2PC impact avalibility
-Solution SALGA:
	- when transaction span multiple service
	SAGA: sequence of local trasasction  of 2 local transaction for each service
	-the whole idea is break up the distributed transaciton into squence of local transaction 
-Compliaiotn of SAGA: 
	-Rollback:	
		-each local trasnation, commited changes, so diff to roolback
		-T1- >T2>T3..if n+1 step fail you need to prom to rollback from ntill 1 undo them
		- main challenge: it t2 , fail and t1 rollback, 
		- return a respone back to client , eg: order ID , : mean order is accepted, client need to poll to check the order status
		- you can communitte with UI, like it will take 30 sec, 
		- businees logic is complation, as each trasaction will commited local T, so other can see that local Transaction
		- if cancel req come, and the status still pending is difficlut to handle.
-Cordination in SAGA:
	- when any T is suicces of fail, there will be some time of prcess that execute and tell what need to do next,
	- we have 2 way for this
		-Choregraphy : ditribtued decision making: saga service handle this among themself
		-Orchestration: centralize decision making
		- this code will run in ach service, will tell other sevie what to do now ,
		- cleaner : orchestrator: saha orchestrator are state mahcine,repsone comes then trasaction to next state
		- 2 : implicit orchetrator
			  Explicit:Dedecated OBJE: trafoff, but improce separation fo concern 
		-createOrcer(): emit and event order created, then c: service will use each othe revenet, they may have cyclic dependency
		- stateless signlfe:: spring beand, State is enum, and data obj, that have presistent data,
		-enum+ saga state in db = state of sage
		-CodE example whne Explicit orchestrator , there is create order sagae obje will act as centralize orhestrator:
		
		  public class CreatOrderSaga implements SATA<CreateOrderStata,CreateOrderSAga>{
			private SagaSTateMachine<CreateOrdersaga,CreateOrderSataData> statteMachine;}
			@postConstruct
			 public void initializeStateMachine(){
				this.statMachine=starting(this::initialize)
				.isinState(createOrderSagaState.RESERVE_CREDIT)
				.replyFROM(customerserviceproxu.reserveceCount)
				.onReply(Success.class, this:handleCredit)
				.onReply(Failure.class,this handleCreditLimitExceed)}
	- use some form of ASYN MSG: REST and RPC , will not give right kidnof gurantee,, we need borker so durable ,
	- REST both service need to be up at same time, 
	-SAGA participant:
		- Subscribe ot commnad cnanne
		-Saga orchestrad
	-Order server> Msg broker> Customer server
	ORder service: CreateOrder Orchestrator 
	- sending msg and updating DB: must be transactional : avoid 2PC
	-Trick: user DB table as temp msg quee, when some serviece update data, local acid transiton, it insert msg in msg table, as local acid gurantee to wrk
		-how to pass msg frm DB to broker?
			- predically Polling to msg table : select * form msg_table: how to indetify new msg,
			- Tranaction  log tailing: change in commmit log,need to monitor , adn pub to msg broker:: this impl is very very DB specifc, 
				-say MYSQL: mobgo has oplog, dynamo db has stream,, so each db have diffrent logs
			- 
------------------------------------------------------------------------------------------
MS: technique for struccturing of an app as collections of services
	- self -contained with clear interface and distinct purpose
	-lossly copuple- commucation over netwrk
	- indepenently deployable ,scable,maintabible,testable
	-MS: communicate primaril with event with API where required
	- Events are handled by events backbone
	-Data is eventually consistent
	-MSGL p2p(Queue,JSM,ordered list, each msg cosume by isngle cosumenr, ) or pub/sub(topics,mutiple sub to sme topic, each sub will have one copy)
	- Kafka: pub-sub:suppurt of tream,storage infra,hold TB of data, connector, event form other system, just plug,
	-Event backbone:producr prodce evnet on EVENt backbone, and consuemr will consume, execution rate of pub and os will be different
	-maintaince on consuenr, without effecting the pub,not possibel in REST
	-Notification:
	- one topic hav eall tranactin> then speare to respctive toic using stream
	-sMs aleart, email alert,push alert, theu call respective SMS API
	- Intefity: Events,Actors,Data,Commands
	-Pattern for event-drivent
		-loose coupling 
		- data consistency : trikle to systme gradually , asyn replicate between node
		-efficent quiers:
	-PATTERN
		-Database per serive:protect form external change, data consistency across micrservice, mongo, in memry db, stream K-table durability if Kafka
		-SAGA::Log compaction, periodic compaciton,
		-Event sourcing 
		-CQRS
		
--------------------------------------------------------------------------------------------------------

KAFKA:A distributed streaming platform
STREA:Streams are just infinite data, data that never end. It just keeping arriving, and you can process it in real-time.
Distributed means that Kafka works in a cluster, each node in the cluster is called Broker. 
rokers are just servers executing a copy of apache Kafka.

Kafka is a set of machines working together to be able to handle and process real-time infinite data.
Brokers is what makes it so resilient, reliable, scalable, and fault-tolerant.

QUEUE SYSTEM:
	-Producer: Who produces and send the messages to one or more queues;
	-Queue: A buffer data structure, that receives (from the producers) and delivers messages (to the consumers) in a FIFO
	-Consumer: Who is subscribed to one or more queues and receives their messages when published
-prod and consumer is samiliar, but here we hve topic not queue
-TOPIC:
	- A topic is divided into partitions, each topic can have one or more partitions and we need to specify that number when we're creating the topic.
	-If we don’t give any key to a message when we’re producing it, by default, the producers will send the message in a round-robin way, each partition will receive a message
	-if we want to send a message always to the same partition, we need to give a key to our messages. 
	-Each message will be stored in the broker disk and will receive an offset (unique identifier). 
	-offset is unique at the partition level, each partition has its owns offsets. 
	- it stores the messages in the disk (like a database, and in fact, Kafka is a database too) to be able to recover them later if necessary.
	-Different from a messaging system, that the message is deleted after being consumed
	-case of consumer failure, when it recovers, will start reading from the last offset
	-A Kafka cluster may contain many brokers as needed.
	-Each broker in a cluster is identified by an ID and contains at least one partition of a topic.
	-he number of the partitions in each broker, we need to configure something called Replication Factor
	=-he number of the partitions match the number of the brokers,
	-To ensure the reliability of the cluster, Kafka enters with the concept of the Partition Leader. 
	-The leader partition is the only one that receives the messages, their replicas will just sync the data
	-When a leader goes down, a replica will be automatically elected as a new leader by Zookeeper.
	-Message 01 goes to partition 0 of Topic 1, and message 02 to partition 1 of the same topic.
	-It means that we can’t guarantee that messages produced by the same producer will always be delivered to the same topic.
	- need to specify a key when sending the message, Kafka will generate a hash based on that key and will know what partition to deliver that message.
	-cknowledgment (ack). The ack is basically a confirmation that the message was delivered
	-ack = 0: When we configure the ack = 0, we’re saying that we don’t want to receive the ack from Kafka. 
	-ack = 1: This is the default configuration, with that we’re saying that we want to receive an ack from the leader of the partition.
	-ack = all: This is the most reliable configuration. We are saying that we want to not only receive a confirmation from the leader but from their replicas as well
	-Consumers are applications subscribed to one or more topics that will read messages from there. They can read from one or more partitions.
	-consumer reads from just one partition, we can ensure the order of the reading, but when a single consumer reads from two or more partitions, it will read in parallel, so, there’s no guarantee of the reading order. 
	- Consumer Groups. 
	-he ideal is to have the same number of consumers in a group that we have as partitions in a topic, in this way, every consumer read from only one.
	- I left some important concepts out of this article, like idempotent producers, compression, transactions, etc,
	
	
	
	



	
	
		
		
		
		
